{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c0085b-1225-4418-a524-558f7380acd6",
   "metadata": {},
   "source": [
    "# PyTorch Lab for Machine Learning (Please note that this is a markdown cell. To execute codes, you need to copy them in a new code cell)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this hands-on lab on **PyTorch**, a powerful and flexible deep learning framework. This lab is designed to help you understand essential PyTorch concepts fundamental for machine learning tasks. By the end of this lab, you will:\n",
    "\n",
    "- Understand how to use PyTorch tensors and perform basic operations.\n",
    "- Learn about broadcasting, matrix manipulations like dot products and views.\n",
    "- Build a simple one-layer neural network from scratch for a binary classification problem.\n",
    "\n",
    "Throughout the lab, you’ll find questions to evaluate your understanding. Make sure to attempt them to reinforce your learning.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. PyTorch Basics\n",
    "\t- Importing PyTorch\n",
    "\t- Tensors and Tensor Operations\n",
    "\t- **Questions**\n",
    "2. Broadcasting in PyTorch\n",
    "\t- Understanding Broadcasting Rules\n",
    "\t- Examples of Broadcasting\n",
    "\t- **Questions**\n",
    "3.\tMatrix Manipulation\n",
    "\t- Dot Product\n",
    "\t- Matrix Multiplication\n",
    "\t- Tensor Views and Reshaping\n",
    "\t- **Questions**\n",
    "4.\tBuilding a Simple Neural Network\n",
    "\t- Problem Definition\n",
    "\t- Data Preparation\n",
    "\t- Model Implementation\n",
    "\t- Training the Model\n",
    "\t- Evaluating the Model\n",
    "\n",
    "\n",
    "# PyTorch Basics\n",
    "\n",
    "## Importing PyTorch\n",
    "\n",
    "First, let’s import the PyTorch library:\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "\n",
    "## Tensors and Tensor Operations\n",
    "\n",
    "A **tensor** is a multi-dimensional array and the basic data structure in PyTorch. Tensors are similar to NumPy arrays but can run on GPUs, which makes them suitable for deep learning.\n",
    "\n",
    "**Creating Tensors**\n",
    "\n",
    "You can create tensors from Python lists or NumPy arrays:\n",
    "```python\n",
    "# From a list\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# From a NumPy array\n",
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "```\n",
    "\n",
    "**Basic Operations**\n",
    "\n",
    "You can perform arithmetic operations on tensors:\n",
    "\n",
    "```python\n",
    "# Addition\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "z = x + y  # or torch.add(x, y)\n",
    "\n",
    "# Subtraction\n",
    "z = x - y  # or torch.sub(x, y)\n",
    "\n",
    "# Element-wise multiplication\n",
    "z = x * y  # or torch.mul(x, y)\n",
    "\n",
    "# Division\n",
    "z = x / y  # or torch.div(x, y)\n",
    "```\n",
    "\n",
    "**Tensor Attributes**\n",
    "\n",
    "Every tensor has attributes that describe its shape, data type, and device (CPU or GPU):\n",
    "\n",
    "```python\n",
    "tensor = torch.rand(3, 4)\n",
    "print(f\"Shape: {tensor.shape}\")\n",
    "print(f\"Data type: {tensor.dtype}\")\n",
    "print(f\"Device: {tensor.device}\")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a24a02-2c39-4457-acfd-f9ec01baea2f",
   "metadata": {},
   "source": [
    "## Questions (Write your solutions in the designated cell for each question.)\n",
    "\n",
    "1.\tCreating Tensors\n",
    "Question: Create a 2x3 tensor filled with ones and a 3x2 tensor filled with random numbers between 0 and 1. **(2 marks)**\n",
    "\n",
    "2.\tTensor Operations\n",
    "Question: Given two tensors a = torch.tensor([2, 4, 6]) and b = torch.tensor([1, 3, 5]), compute the element-wise product and sum of these tensors. **(2 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86bc6b-5898-4668-ab2c-d13e6bed93b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725f74d-9374-425d-8056-87c04168d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qestion 1 (Code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3daba8b-6043-417f-86c0-e8150c2c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 (Code cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208879d-2506-4cb0-beb1-1a2342dfce05",
   "metadata": {},
   "source": [
    "# Broadcasting in PyTorch\n",
    "\n",
    "**Broadcasting** is a mechanism that allows PyTorch to perform arithmetic operations on tensors of different shapes by automatically expanding their dimensions to be compatible.\n",
    "\n",
    "## Understanding Broadcasting Rules\n",
    "\n",
    "Broadcasting follows these rules:\n",
    "\n",
    "1. **Align Dimensions:** If the tensors have different numbers of dimensions, the tensor with fewer dimensions is padded with ones on its leading (left) side.\n",
    "2.\t**Dimensions Compatibility:** For each dimension, the sizes are either the same or one of them is 1. In the latter case, the tensor with size 1 in that dimension is expanded to match the other tensor’s size.\n",
    "3.\t**Error Handling:** If in any dimension the sizes disagree and neither is 1, an error is raised.\n",
    "\n",
    "\n",
    "Examples of Broadcasting\n",
    "\n",
    "```python\n",
    "# Example 1\n",
    "a = torch.tensor([1, 2, 3])        # Shape: (3,)\n",
    "b = torch.tensor([[4], [5], [6]])  # Shape: (3, 1)\n",
    "result = a + b                     # Shape: (3, 3)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**\n",
    "```python\n",
    "tensor([[5, 6, 7],\n",
    "        [6, 7, 8],\n",
    "        [7, 8, 9]])\n",
    "```\n",
    "\n",
    "```python\n",
    "# Example 2\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3)\n",
    "result = a + b  # b is broadcasted to shape (2, 3)\n",
    "print(result.shape)  # Output: torch.Size([2, 3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847cc44-f190-4ead-92e1-52c4016bdb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d697f-e2be-46fb-a487-027cf3f5de35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22013c9f-41fc-4078-aef9-6c5d503e6673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87ad50-4be2-441b-a309-0b26a685edb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08e375-ff5e-43cf-9d8c-262eb85644d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca9e1bf-c0bd-436a-af46-b44b7eeb8e99",
   "metadata": {},
   "source": [
    "## Questions (Write your solutions in the designated cell for each question.)\n",
    "\n",
    "3.\tBroadcasting Addition\n",
    "Question: Given a = torch.tensor([[1], [2], [3]]) (shape (3, 1)) and b = torch.tensor([4, 5, 6]) (shape (3,)), what is the shape of a + b and why? **(2 marks)**\n",
    "\n",
    "4.\tError in Broadcasting\n",
    "Question: Given a = torch.rand(2, 3) and b = torch.rand(4, 3), will a + b work? Explain why or why not.**(2 marks)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07719f59-c540-4fd6-8341-ee6f12d25ea7",
   "metadata": {},
   "source": [
    "**Question 3 (Markdown cell):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4e2f-e844-49db-9c52-bb89e6a86c28",
   "metadata": {},
   "source": [
    "**Question 4 (Markdown cell)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241445e-f617-4c04-8781-63df7fccd020",
   "metadata": {},
   "source": [
    "## Matrix Manipulation\n",
    "\n",
    "**Dot Product**\n",
    "\n",
    "The **dot product** is an operation that takes two equal-length sequences of numbers (vectors) and returns a single number.\n",
    "```python\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "dot_product = torch.dot(a, b)\n",
    "print(dot_product)  # Output: tensor(32)\n",
    "```\n",
    "\n",
    "## Matrix Multiplication\n",
    "\n",
    "For matrix multiplication, use torch.mm() or the @ operator.\n",
    "\n",
    "```python\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 4)\n",
    "result = torch.mm(a, b)  # or result = a @ b\n",
    "print(result.shape)  # Output: torch.Size([2, 4])\n",
    "```\n",
    "\n",
    "## Tensor Views and Reshaping\n",
    "\n",
    "Views allow you to change the shape of a tensor without changing its data.\n",
    "\n",
    "```python\n",
    "x = torch.rand(4, 4)\n",
    "y = x.view(16)        # Flatten to 1D tensor with 16 elements\n",
    "z = x.view(-1, 8)     # Reshape to a 2D tensor with 8 columns\n",
    "print(y.shape)        # Output: torch.Size([16])\n",
    "print(z.shape)        # Output: torch.Size([2, 8])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89418b-d51d-47fe-9184-e6c54cd32594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d71dc2-baa2-453c-961c-1034bb66b01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb76759-f417-4b5c-ad4d-02ec8c9666e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a247d-008a-4266-82b9-f4d9fe3a6836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38a95b-05c6-4288-9412-6e1f4132fef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e821327b-0f37-4a5b-8a5c-368d5b775ff4",
   "metadata": {},
   "source": [
    "## Questions (Write your solutions in the designated cell for each question.)\n",
    "5. Compute the dot product of a = torch.tensor([2, 5, 1]) and b = torch.tensor([3, 0, 4]).**(2marks)**\n",
    "6. If a has shape (5, 3) and b has shape (3, 2), what will be the shape of torch.mm(a, b)?**(2marks)**\n",
    "7. Given a tensor x = torch.rand(2, 3, 4), reshape it to have shape (4, 6) using view.**(2marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b80ce9-ab4b-4788-b126-b7fba95ee77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 (code cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33028a-6541-465c-ba8b-e7a7f3f5c0e6",
   "metadata": {},
   "source": [
    "Question 6 (Markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fc846-ea36-473a-ad4c-2e768ddad03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7 (code cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b008dd4-0532-461c-aa83-f0b7e206762d",
   "metadata": {},
   "source": [
    "# Building a Simple Neural Network\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "We will build a simple one-layer neural network from scratch to perform binary classification on a synthetic dataset.\n",
    "\n",
    "**Data Preparation**\n",
    "\n",
    "First, let’s create a synthetic dataset using make_blobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33905a3-83e6-4493-848e-f2261fc2a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamadkhajezade/workspace/implementing-a-binary-classifier-with-pytorch/env/lib/python3.9/site-packages/torch/_subclasses/functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "X_numpy, y_numpy = make_blobs(n_samples=100, centers=2, n_features=2, random_state=0)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.from_numpy(X_numpy).float()\n",
    "y = torch.from_numpy(y_numpy).float().view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001608a7-3404-43a8-961f-626ae6e17616",
   "metadata": {},
   "source": [
    "# Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f604d10-61e6-4938-9f6e-d12bfcec2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_numpy[:, 0], X_numpy[:, 1], c=y_numpy, cmap='coolwarm')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Synthetic Binary Classification Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3ef87-b780-4131-a056-55ec1561d09e",
   "metadata": {},
   "source": [
    "# Model Implementation \n",
    "\n",
    "We will implement a one-layer neural network manually.\n",
    "\n",
    "**Initialize Parameters ((In the code, there are 2 marks that you need to complete))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bc38d-1ad5-422c-b36e-ff7e85109754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "torch.manual_seed(0)\n",
    "weights = # Randomly initialize a tensor of shape (2, 1). the requires_grad should be true (2 marks)\n",
    "bias = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e9914-29e6-4019-bbf0-6e92e008b0c9",
   "metadata": {},
   "source": [
    "# Define the Model (In the code, there are 2 marks that you need to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d0d45-3bc3-48f4-970b-6c5fefa93a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    return torch.sigmoid() # Multiply weights and inputs and add the bias as the input of the sigmoid function (2 marks) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af163a5-3ffd-4728-89f8-843ccbf0cc48",
   "metadata": {},
   "source": [
    "# Define the Loss Function\n",
    "\n",
    "We will use the Binary **Cross-Entropy** Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f7fe2-ab9d-497c-8975-0e4a69e38c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_pred, y_true):\n",
    "    epsilon = 1e-7  # To avoid log(0)\n",
    "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = - (y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa95b07-fc8f-4fc2-bb49-d586e5c19be0",
   "metadata": {},
   "source": [
    "# Training the Model (In the code, there are 6 marks that you need to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17ceaa-b109-4ad6-bfe9-81de16cd3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = # Perform prediction (2 marks)\n",
    "    loss = # Calculate loss (2 marks)\n",
    "    \n",
    "    # Backward pass\n",
    "    # Perform back propagation to calculate gradients (2 marks)\n",
    "    \n",
    "    # Update parameters\n",
    "    with torch.no_grad():\n",
    "        weights -= learning_rate * weights.grad\n",
    "        bias -= learning_rate * bias.grad\n",
    "    \n",
    "    # Zero gradients\n",
    "    weights.grad.zero_()\n",
    "    bias.grad.zero_()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0cb73-fe9f-4019-b914-9c8d7540f453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
